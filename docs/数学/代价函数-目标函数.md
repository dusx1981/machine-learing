## 目标函数与代价函数：数学原理与关系详解

我将通过清晰的数学推导和具体示例，深入说明目标函数与代价函数的关系。

### 1. 核心概念区分

#### 1.1 目标函数（Objective Function）
**定义**：在优化问题中需要最大化或最小化的函数
- **最大化**：如利润、准确率、似然函数
- **最小化**：如成本、误差、损失

数学表达：
$$
\text{目标：} \min_{x \in \mathcal{X}} f(x) \quad \text{或} \quad \max_{x \in \mathcal{X}} f(x)
$$

#### 1.2 代价函数（Cost Function）/损失函数（Loss Function）
**定义**：衡量模型预测值与真实值之间差异的函数
- 总是需要最小化
- 通常是目标函数的核心组成部分

#### 1.3 关键关系
**代价函数 ⊆ 目标函数**
目标函数 = 代价函数 + 正则化项 + 其他约束

### 2. 数学原理：从概率视角的统一

#### 2.1 监督学习的概率框架
给定数据 $ D = \{(x_i, y_i)\}_{i=1}^n $，参数 $\theta$：

**最大似然估计视角**：
$$
\text{目标：最大化似然} \quad L(\theta) = P(D|\theta)
$$
等价于：
$$
\text{最小化负对数似然} \quad J(\theta) = -\log L(\theta)
$$
这里，负对数似然函数 **就是代价函数**。

#### 2.2 贝叶斯视角的扩展
在贝叶斯框架中，考虑参数先验：
$$
\text{目标：最大后验估计} \quad \theta_{\text{MAP}} = \arg\max_{\theta} P(\theta|D)
$$
由贝叶斯定理：
$$
P(\theta|D) \propto P(D|\theta)P(\theta)
$$
取对数：
$$
\log P(\theta|D) = \log P(D|\theta) + \log P(\theta) + \text{常数}
$$
最大化后验等价于：
$$
\text{最小化：} \underbrace{-\log P(D|\theta)}_{\text{代价函数（似然项）}} \underbrace{-\log P(\theta)}_{\text{正则化项（先验项）}}
$$
这就是**包含正则化的目标函数**。

### 3. 具体示例分析

#### 示例1：线性回归（对比说明）

**问题设定**：数据 $ (x_i, y_i) $，模型 $ \hat{y}_i = \theta^T x_i $

##### 版本1：普通最小二乘（只有代价函数）
**代价函数**（均方误差）：
$$
J(\theta) = \frac{1}{2n}\sum_{i=1}^n (y_i - \theta^T x_i)^2
$$
**目标函数** = 代价函数（因为没有其他项）：
$$
\text{目标：} \min_{\theta} J(\theta)
$$

##### 版本2：岭回归（L2正则化）
**代价函数**（仍为均方误差）：
$$
\text{Cost}(\theta) = \frac{1}{2n}\sum_{i=1}^n (y_i - \theta^T x_i)^2
$$
**目标函数**（包含正则化）：
$$
\text{Objective}(\theta) = \underbrace{\frac{1}{2n}\sum_{i=1}^n (y_i - \theta^T x_i)^2}_{\text{代价函数}} + \underbrace{\lambda \|\theta\|_2^2}_{\text{正则化项}}
$$

##### 版本3：贝叶斯视角解释
假设：
1. 似然：$ y_i \sim N(\theta^T x_i, \sigma^2) $
2. 先验：$ \theta_j \sim N(0, \tau^2) $

负对数后验：
$$
-\log P(\theta|D) = \underbrace{\frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - \theta^T x_i)^2}_{\text{代价函数（负对数似然）}} + \underbrace{\frac{1}{2\tau^2}\sum_{j=1}^d \theta_j^2}_{\text{正则化项（负对数先验）}} + \text{常数}
$$
这正是岭回归的目标函数，其中 $ \lambda = \sigma^2/\tau^2 $。

#### 示例2：逻辑回归的演进

**问题设定**：二分类，$ y_i \in \{0,1\} $，$ h_\theta(x) = \sigma(\theta^T x) = 1/(1+e^{-\theta^T x}) $

##### 步骤1：定义代价函数（交叉熵损失）
单个样本的损失：
$$
\ell(y, \hat{y}) = -[y\log\hat{y} + (1-y)\log(1-\hat{y})]
$$
代价函数（经验风险）：
$$
J(\theta) = -\frac{1}{n}\sum_{i=1}^n [y_i\log h_\theta(x_i) + (1-y_i)\log(1-h_\theta(x_i))]
$$

##### 步骤2：添加正则化得到目标函数
L2正则化版本：
$$
\text{Objective}(\theta) = J(\theta) + \frac{\lambda}{2}\|\theta\|_2^2
$$

L1正则化版本：
$$
\text{Objective}(\theta) = J(\theta) + \lambda\|\theta\|_1
$$

##### 步骤3：概率解释
假设 $ y_i \sim \text{Bernoulli}(h_\theta(x_i)) $，先验 $ \theta \sim N(0, \tau^2 I) $

负对数后验：
$$
-\log P(\theta|D) = -\sum_{i=1}^n [y_i\log h_\theta(x_i) + (1-y_i)\log(1-h_\theta(x_i))] + \frac{1}{2\tau^2}\|\theta\|_2^2 + \text{常数}
$$
第一项是代价函数，第二项是正则化项。

#### 示例3：支持向量机（SVM）

**原始问题**（最大间隔分类）：
$$
\text{目标：最大化间隔} \quad \text{等价于} \quad \text{最小化} \ \frac{1}{2}\|w\|_2^2
$$
约束：$ y_i(w^T x_i + b) \geq 1 $

**引入软间隔**（允许错分）：
代价函数（合页损失）：
$$
\text{Cost}(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))
$$
其中 $ f(x_i) = w^T x_i + b $

**完整目标函数**：
$$
\text{Objective}(w, b) = \underbrace{\frac{1}{2}\|w\|_2^2}_{\text{正则化项（最大化间隔）}} + \underbrace{C\sum_{i=1}^n \max(0, 1 - y_i f(x_i))}_{\text{代价函数（合页损失）}}
$$
参数 $ C $ 控制正则化强度与代价的权衡。

### 4. 一般化数学框架

#### 4.1 监督学习的优化问题
对于参数 $ \theta $：

**目标函数的一般形式**：
$$
\mathcal{J}(\theta) = \underbrace{\frac{1}{n}\sum_{i=1}^n \ell(y_i, f_\theta(x_i))}_{\text{经验代价（损失）}} + \underbrace{\lambda \cdot \Omega(\theta)}_{\text{正则化项}}
$$

其中：
- $ \ell(\cdot) $：损失函数，衡量单个样本的误差
- $ \Omega(\theta) $：正则化函数，控制模型复杂度
- $ \lambda $：超参数，权衡两项重要性

#### 4.2 不同视角的统一

| 视角 | 代价函数部分 | 正则化部分 | 对应目标函数 |
|------|-------------|-----------|-------------|
| 频率派 | 经验风险 | 显式约束 | 带约束的优化 |
| 贝叶斯 | 负对数似然 | 负对数先验 | 最大后验估计 |
| 优化理论 | 数据拟合项 | 复杂度惩罚项 | 正则化风险最小化 |

#### 4.3 具体数学转换示例

**从最大似然到正则化目标函数**：

假设数据生成：$ y_i \sim N(f_\theta(x_i), \sigma^2) $
先验：$ \theta \sim N(0, \tau^2 I) $

1. **似然函数**：
$$
L(\theta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - f_\theta(x_i))^2}{2\sigma^2}\right)
$$

2. **后验分布**：
$$
P(\theta|D) \propto L(\theta) \cdot \exp\left(-\frac{\|\theta\|_2^2}{2\tau^2}\right)
$$

3. **负对数后验（目标函数）**：
$$
-\log P(\theta|D) = \underbrace{\frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - f_\theta(x_i))^2}_{\text{代价函数}} + \underbrace{\frac{1}{2\tau^2}\|\theta\|_2^2}_{\text{正则化项}} + \text{常数}
$$

令 $ \lambda = \sigma^2/\tau^2 $，得到常见形式：
$$
\mathcal{J}(\theta) = \sum_{i=1}^n (y_i - f_\theta(x_i))^2 + \lambda \|\theta\|_2^2
$$

### 5. 数值计算示例

#### 示例：线性回归对比

**数据**：$ x = [1, 2, 3]^T $，$ y = [2, 4, 6]^T $
**模型**：$ \hat{y} = \theta x $（简单线性，无截距）

##### 情况1：只有代价函数（最小二乘）
代价函数：
$$
J(\theta) = \frac{1}{6}[(2-\theta)^2 + (4-2\theta)^2 + (6-3\theta)^2]
$$
求导：
$$
\frac{dJ}{d\theta} = \frac{1}{3}[(2-\theta) + 2(4-2\theta) + 3(6-3\theta)] = \frac{1}{3}(28 - 14\theta) = 0
$$
解得：$ \theta = 2 $

##### 情况2：添加L2正则化（λ=1）
目标函数：
$$
\mathcal{J}(\theta) = J(\theta) + \theta^2 = \frac{1}{6}[(2-\theta)^2 + (4-2\theta)^2 + (6-3\theta)^2] + \theta^2
$$
求导：
$$
\frac{d\mathcal{J}}{d\theta} = \frac{1}{3}(28 - 14\theta) + 2\theta = \frac{28}{3} - \frac{14}{3}\theta + 2\theta = \frac{28}{3} - \frac{8}{3}\theta = 0
$$
解得：$ \theta = 3.5 $

**对比结果**：
- 无正则化：$ \theta = 2.0 $（完美拟合数据）
- 有正则化：$ \theta = 3.5 $（参数值缩小，防止过拟合）

### 6. 总结：目标函数与代价函数的关系

#### 6.1 核心关系总结
1. **层次关系**：
   - 代价函数是目标函数的**核心组成部分**
   - 目标函数 = 代价函数 + 正则化项 + 其他约束

2. **优化视角**：
   - 代价函数衡量**数据拟合程度**
   - 正则化项衡量**模型复杂度**
   - 目标函数权衡两者，实现**偏差-方差平衡**

3. **概率视角**：
   - 代价函数对应**负对数似然**（数据项）
   - 正则化项对应**负对数先验**（惩罚项）
   - 目标函数对应**负对数后验**

#### 6.2 实用指导
1. **设计目标函数的步骤**：
   - 步骤1：根据任务选择代价函数（损失函数）
     - 回归：均方误差、绝对误差
     - 分类：交叉熵、合页损失
   - 步骤2：根据需求添加正则化项
     - L2正则化：使参数平滑
     - L1正则化：获得稀疏解
     - 混合正则化（Elastic Net）

2. **超参数的作用**：
   - λ控制正则化强度
   - λ → 0：接近纯代价函数最小化
   - λ → ∞：强正则化，模型趋向简单

3. **验证方法**：
   - 使用验证集调整λ
   - 监控训练误差 vs 验证误差
   - 防止过拟合（高方差）或欠拟合（高偏差）

这种框架不仅适用于传统机器学习，也适用于深度学习、强化学习等领域，是理解模型优化本质的关键。