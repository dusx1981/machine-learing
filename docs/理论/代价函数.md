# 损失函数、代价函数与目标函数的设计思想与数学原理分析

## 1. 基本概念与层次关系

### 概念层次
```
损失函数 (Loss Function) → 代价函数 (Cost Function) → 目标函数 (Objective Function)
```

**损失函数**：衡量单个样本的预测误差  
**代价函数**：衡量整个训练集的平均误差  
**目标函数**：最终要优化的函数（可能包含正则化项）

## 2. 损失函数 (Loss Function)

### 设计思想
损失函数度量模型对**单个样本**的预测质量，核心思想是：
- 预测越准确，损失值越小
- 预测越错误，损失值越大
- 应该是连续可微的（便于优化）

### 常见损失函数及其数学原理

#### 2.1 平方损失 (Squared Loss)
$$L(y, \hat{y}) = (y - \hat{y})^2$$

**数学原理**：
- 对应**极大似然估计**：假设误差服从高斯分布
- 导数简单：$\nabla L = 2(y - \hat{y})$
- 对异常值敏感（平方放大了大误差）

#### 2.2 绝对损失 (Absolute Loss)
$$L(y, \hat{y}) = |y - \hat{y}|$$

**数学原理**：
- 对应拉普拉斯分布的极大似然估计
- 对异常值更鲁棒
- 在零点不可微

#### 2.3 交叉熵损失 (Cross-Entropy Loss)
$$L(y, \hat{y}) = -[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$$

**数学原理**：
- 源于信息论，衡量两个概率分布的差异
- 对应伯努利分布的极大似然估计
- 在分类问题中梯度性质良好

## 3. 代价函数 (Cost Function)

### 设计思想
代价函数聚合所有样本的损失，提供模型在**整个数据集**上的性能评估：

$$J(\theta) = \frac{1}{m} \sum_{i=1}^m L(y^{(i)}, f(x^{(i)}; \theta))$$

### 数学原理分析

#### 3.1 经验风险最小化 (Empirical Risk Minimization)
代价函数实现了经验风险最小化原则：
$$\hat{\theta} = \arg\min_{\theta} \frac{1}{m} \sum_{i=1}^m L(y^{(i)}, f(x^{(i)}; \theta))$$

**大数定律保证**：当样本数 $m \to \infty$ 时，经验风险收敛于期望风险。

#### 3.2 凸性设计
良好的代价函数应该具有凸性：
- 保证存在全局最优解
- 便于梯度下降等优化算法收敛

**海森矩阵正定**：对于平方损失，海森矩阵 $\nabla^2 J$ 是半正定的，保证凸性。

## 4. 目标函数 (Objective Function)

### 设计思想
目标函数在代价函数基础上引入**正则化项**，平衡拟合优度与模型复杂度：

$$\text{Objective} = \text{Cost Function} + \lambda \cdot \text{Regularization}$$

### 正则化的数学原理

#### 4.1 L2 正则化 (岭回归)
$$J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m} \sum_{j=1}^n \theta_j^2$$

**贝叶斯解释**：对应高斯先验的极大后验估计(MAP)  
**几何解释**：限制参数空间，防止过拟合

#### 4.2 L1 正则化 (Lasso)
$$J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m} \sum_{j=1}^n |\theta_j|$$

**数学特性**：产生稀疏解，自动特征选择

## 5. 具体案例分析：线性回归

### 代价函数设计
$$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^m (\theta_0 + \theta_1 x_i - y_i)^2$$

#### 设计原理：
1. **平方项**：放大大误差的惩罚，便于数学处理
2. **1/2系数**：求导后消去平方产生的系数2，简化计算
3. **平均项(1/m)**：消除样本数量对梯度大小的影响

#### 概率解释：
假设真实关系为：$y = \theta_0 + \theta_1 x + \varepsilon$，其中 $\varepsilon \sim N(0, \sigma^2)$

似然函数：
$$L(\theta) = \prod_{i=1}^m \frac{1}{\sqrt{2\pi}\sigma} \exp\left(-\frac{(y_i - (\theta_0 + \theta_1 x_i))^2}{2\sigma^2}\right)$$

负对数似然：
$$-\log L(\theta) = \frac{1}{2\sigma^2} \sum_{i=1}^m (y_i - (\theta_0 + \theta_1 x_i))^2 + \text{常数}$$

**结论**：最小化平方损失等价于在高斯噪声假设下的极大似然估计。

## 6. 梯度下降的数学原理

### 一阶优化方法
$$\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$$

#### 泰勒展开视角：
在 $\theta$ 附近一阶泰勒展开：
$$J(\theta + \Delta\theta) \approx J(\theta) + \nabla J(\theta)^T \Delta\theta$$

选择 $\Delta\theta = -\alpha\nabla J(\theta)$ 保证函数值下降。

#### 学习率选择：
- 太大：可能发散
- 太小：收敛缓慢
- 自适应方法：Adam, RMSProp 等

## 7. 泛化与正则化的深入分析

### 偏差-方差权衡
$$\mathbb{E}[(y - \hat{f}(x))^2] = \text{Bias}^2(\hat{f}(x)) + \text{Var}(\hat{f}(x)) + \sigma^2$$

**正则化作用**：
- 增大偏差（模型变得更简单）
- 减小方差（降低对训练数据的敏感度）
- 优化泛化误差

## 8. 总结

### 设计哲学
1. **损失函数**：基于概率假设（高斯→平方损失，伯努利→交叉熵）
2. **代价函数**：实现经验风险最小化，保证统计一致性
3. **目标函数**：引入归纳偏置，控制模型复杂度

### 数学基础
- **优化理论**：凸分析、梯度方法
- **概率论**：极大似然估计、贝叶斯推断
- **统计学习理论**：VC维、泛化误差界

这种层次化的函数设计为机器学习提供了坚实的理论基础和实用的优化框架。